{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask and No Mask Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the file with_mask.npy and without_mask.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_mask = np.load('with_mask.npy')\n",
    "without_mask = np.load('without_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50, 50, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the dimension of the with_mask images\n",
    "with_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50, 50, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the dimension of the without_mask images\n",
    "without_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting 4 dimensional data into two dimensional\n",
    "#both with and without mask contains 200 images with 7500 columns\n",
    "with_mask = with_mask.reshape(200,50 * 50 * 3)\n",
    "without_mask = without_mask.reshape(200, 50 * 50 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#again checking the dimension of with and without mask after reshaping them\n",
    "with_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the data\n",
    "#r_ in NumPy is used for concatination the rows of the data\n",
    "X= np.r_[with_mask, without_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 7500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the shape of the X it is done for preparing the training data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels is for y since we have total of 400 images\n",
    "labels = np.zeros(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first 200 will point to with_mask images and 1.0 will point to without_mask images\n",
    "labels[200:] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if wearing mask the output will be 0 and if not wearing a mask output will be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {0 : 'Mask', 1: 'No Mask'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "It is the combiantion of program and maths.It is a type of artificial intelligence that allows software applications to become more accurate at predicting outcomes without being explicitly programmed to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn\n",
    "\n",
    " It is one of the library machine learinig in pyhton used for predicitive data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vectore Machine\n",
    "\n",
    "It is a set of supervised learning method used for detecting outliers, classification and regression detection. It is used because it is effective in high dimensional spaces implementation as well as it is useful in data where number of dimensions is greater than the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " #svm - support Vector Machine\n",
    " #svc - support vector classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score # to check the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dividing the data into training and testing split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,training part will be used to apply the machine learning and testing part is used to perform and check the predictions, outcomes of the trained models.Also we are using 20 percent of data will be reserved for testing and the remaining 80 percent of data will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have divided the data into training and testing machine learning will be applied on 300 images not on 400 images. On the reamining 100 images we will test the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 7500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can notice that we have 7500 columns which is a problem resulting the program into slowing down the machine learning algorithm so now we can reduce the dimension using dimensionality reduction inorder to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis\n",
    "\n",
    "It is a dimensionality-reduction method used to often reduce the dimensionality of a large data sets by transforming a large set of variables into a smaller one which contains most of the information in the large set.\n",
    "\n",
    "##### Dimesionality Reduction\n",
    "It is the transformation of data from high dimensional space into loe dimensional space so that the low dimensional ones contains some meaningful properties of the original data, close to intrinsic dimesion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensionality reduction\n",
    "#PCA - principal Component Analysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)#it will make the data into 3 columns\n",
    "x_train = pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimentionality reduction uses Eigen Value and Eigen Vector to reduce the dimensions\n",
    "\n",
    "### Eigen Value and Eigen Vectors\n",
    "\n",
    "Eigen vectors are those unique vectors that do not chnage their direction when a linear transformation is performed on them. Whereas, Eigen value is the corresponding value number by which it is stretched or compressed due to linear transformation. Eigen valus is denoted by λ. It is calculated as Av-λv=0 where A is a square matrix and v is non zero vector and λ is eigen value.\n",
    "\n",
    "It is calculated as follows:\n",
    "For 2 dimension:\n",
    "A=np.array([[5,3 ],[4,2]])\n",
    "eigen_values,eigen_vectors=la.eig(A)\n",
    "Ans: eigen values : [ 7.27491722 -0.27491722]\n",
    "eigen vectors : \n",
    " [[ 0.79681209 -0.49436913]\n",
    " [ 0.60422718  0.86925207]]\n",
    "\n",
    "For 3 dimesion:\n",
    "A=np.array([[-6, 3,4],[4,5,6],[2,7,4]])\n",
    "la.eig(A)\n",
    "eigen_values,eigen_vectors=la.eig(A)\n",
    "Ans: eigen values:  [12.17784334 -6.88932678 -2.28851657]\n",
    "eigen vectors:  [[-0.26169477 -0.93968193  0.19988471]\n",
    " [-0.70067295  0.3390297  -0.68579189]\n",
    " [-0.66375693 -0.0453512   0.69981111]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2340.25679839,  -84.74290094,  -93.93557389])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test = pca.transform(x_test)\n",
    "y_pred = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the accuracy score was 1.0 in the beginning due to overfitting so we had to reshuffled the data until we got accurracy score we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4875"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the actual test data and the prediction data\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detector starting the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "No Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "No Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "No Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "No Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n",
      "No Mask\n"
     ]
    }
   ],
   "source": [
    "haar_data = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "capture = cv2.VideoCapture(0)\n",
    "data = []\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "while True:\n",
    "    flag, img = capture.read()\n",
    "    if flag:\n",
    "        faces = haar_data.detectMultiScale(img)\n",
    "        for x,y,w,h in faces:\n",
    "            cv2.rectangle(img,(x,y), (x+w, y+h), (255,0,255), 4)\n",
    "            #fetcing face of the image\n",
    "            face = img[y:y+h, x:x+w, :]\n",
    "            face = cv2.resize(face, (50,50))\n",
    "            face = face.reshape(1, -1)\n",
    "            #face = pca.transform(face)\n",
    "            pred = svm.predict(face)\n",
    "            n = names[int(pred)]\n",
    "            cv2.putText(img, n, (x,y), font, 1, (244,250,250), 2)\n",
    "            print(n)\n",
    "        cv2.imshow('result',img)\n",
    "        #27 is the ASCII value of escape\n",
    "        if cv2.waitKey(2) == 27:\n",
    "            break\n",
    "            \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
